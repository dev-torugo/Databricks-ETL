{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(url:str):\n",
    "  filename = url.split('/')[-1]\n",
    "  with requests.get('https://datahub.io/core/glacier-mass-balance/r/glaciers.csv', stream=True) as r:\n",
    "    with open(\"/dbfs/{}\".format(filename), 'wb') as f:\n",
    "      for chunk in r.iter_content(chunk_size=8192):\n",
    "        f.write(chunk)\n",
    "  return filename\n",
    "\n",
    "def read_data(file_name):\n",
    "  if file_format == 'csv':\n",
    "    df = spark.read.format(file_format).option(\"header\",\"true\").load(\"file:/dbfs/{}\".format(file_name))\n",
    "  elif file_format == 'json':\n",
    "    try:\n",
    "      df = spark.read.format(file_format).load(\"file:/dbfs/{}\".format(file_name))\n",
    "    except:\n",
    "      df = spark.read.format(file_format).option(\"multiline\",\"true\").load(\"file:/dbfs/{}\".format(file_name))\n",
    "  elif file_format == 'parquet':\n",
    "    df = spark,read.format(file_format).load(\"file:/dbfs/{}\".format(file_name))\n",
    "  elif file_format == 'txt':\n",
    "    df = spark.read.text(\"file:/dbfs/{}\".format(file_name))\n",
    "  return df\n",
    "\n",
    "def transform_data(df: DataFrame):\n",
    "  spark.sql(\"create or replace temp view nintys as select * from df where Year like '19%' order by Year asc;\")\n",
    "  sec_20_df = spark.sql(\"select * from nintys\")\n",
    "  spark.sql(\"create or replace temp view modern as select * from df where Year like '20%' order by Year asc;\")\n",
    "  sec_21_df = spark.sql(\"select * from modern\")\n",
    "  return sec_20_df, sec_21_df\n",
    "\n",
    "def create_file_names():\n",
    "  sec_20_file_names = spark.sql(\"(select * from nintys order by Year ASC limit 1) union (select * from nintys order by Year DESC limit 1)\")\n",
    "  sec_21_file_names = spark.sql(\"(select * from modern order by Year ASC limit 1) union (select * from modern order by Year DESC limit 1)\")\n",
    "  sec_21_file_names = sec_20_file_names.collect()\n",
    "  sec_21_file_names_df = sec_21_file_names.collect()\n",
    "  sec_20_file_names = sec_21_file_names[0].__getitem__('Year') + \"-\" + sec_21_file_names[1].__getitem__('Year') \n",
    "  sec_21_file_name = sec_21_file_names_df[0].__getitem__('Year') + \"-\" + sec_21_file_names_df[1].__getitem__('Year') \n",
    "  return sec_20_file_names, sec_21_file_name\n",
    "d\n",
    "def write_df(file_type: str,dfs, file_names):\n",
    "  for x,y in zip(dfs,file_names):\n",
    "    sec_21 = x.write.format(file_type).save(\"/dbfs/{}.{}\".format(y, file_type))\n",
    "  return sec_21 \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = get_data('https://datahub.io/core/glacier-mass-balance/r/glaciers.csv')\n",
    "spark.read.format(\"csv\").option(\"header\",\"true\").load(\"file:/dbfs/glacier.csv\")\n",
    "file_format = file_name.split(\".\")[-1]\n",
    "\n",
    "df = read_data(file_name)\n",
    "\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "sec_20, sec_21 = create_file_names()\n",
    "\n",
    "write_df(\"parquet\",[x, y],[sec_20, sec_21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.ls('/dbfs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
